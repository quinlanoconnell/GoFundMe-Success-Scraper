{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Group Names: Quinlan OConnell, Samay Mohapatra, Sebastian Martinez, Shyam Patel, Vinay Sangamalli, Justin Yang"
      ],
      "metadata": {
        "id": "_qeKvS40Li3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPBOdrEUtrKf",
        "outputId": "4c68ae0d-c571-457b-a601-8db54f60ee27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "GOFUNDME PREDICTIVE ANALYSIS - TASKS C & D\n",
            "============================================================\n",
            "\n",
            "üìÇ Loading data...\n",
            "‚úì Loaded 1000 campaigns\n",
            "\n",
            "üîç Checking for missing values...\n",
            "image_labels      1\n",
            "description       0\n",
            "amount_raised     0\n",
            "duration_days    10\n",
            "dtype: int64\n",
            "============================================================\n",
            "TASK C: Binary Target Variable Created\n",
            "============================================================\n",
            "Median amount raised: $1,585.00\n",
            "\n",
            "Class distribution:\n",
            "binary\n",
            "0    498\n",
            "1    502\n",
            "Name: count, dtype: int64\n",
            "\n",
            "High $$ (binary=1): 502 campaigns\n",
            "Low $$ (binary=0): 498 campaigns\n",
            "============================================================\n",
            "\n",
            "‚úì Saved to 'campaigns_with_binary.csv'\n",
            "\n",
            "============================================================\n",
            "MODEL 1: Using IMAGE_LABELS\n",
            "============================================================\n",
            "   ‚ÑπÔ∏è  Duration: filled 10 missing values with median (9.0)\n",
            "\n",
            "============================================================\n",
            "MODEL: Image Labels + Duration\n",
            "============================================================\n",
            "Training samples: 800\n",
            "Testing samples: 200\n",
            "Number of features: 101\n",
            "\n",
            "üìä ACCURACY: 0.8400 (84.00%)\n",
            "   (Formula: 1 - 32/200 = 0.8400)\n",
            "\n",
            "üìã CONFUSION MATRIX:\n",
            "                  Predicted\n",
            "                  Low(0)  High(1)\n",
            "Actual  Low(0)      85      15\n",
            "        High(1)     17      83\n",
            "\n",
            "üìà CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Low $$       0.83      0.85      0.84       100\n",
            "     High $$       0.85      0.83      0.84       100\n",
            "\n",
            "    accuracy                           0.84       200\n",
            "   macro avg       0.84      0.84      0.84       200\n",
            "weighted avg       0.84      0.84      0.84       200\n",
            "\n",
            "\n",
            "‚úì Confusion matrix saved as: confusion_matrix_Image_Labels__Duration.png\n",
            "\n",
            "üîù TOP 15 WORDS PREDICTING HIGH FUNDRAISING:\n",
            "   action               (+2.1535)\n",
            "   green                (+2.1162)\n",
            "   photo                (+1.7877)\n",
            "   celebration          (+1.7708)\n",
            "   girls                (+1.6245)\n",
            "   gymnasium            (+1.5094)\n",
            "   tennis               (+1.4986)\n",
            "   coaches              (+1.3674)\n",
            "   clothing             (+1.3480)\n",
            "   helmets              (+1.1213)\n",
            "   sport                (+0.9295)\n",
            "   trophy               (+0.8655)\n",
            "   formal               (+0.8496)\n",
            "   community            (+0.8278)\n",
            "   coach                (+0.7703)\n",
            "\n",
            "üîª TOP 15 WORDS PREDICTING LOW FUNDRAISING:\n",
            "   flag                 (-1.9149)\n",
            "   coaching             (-1.8203)\n",
            "   white                (-1.6784)\n",
            "   branding             (-1.5757)\n",
            "   child                (-1.5563)\n",
            "   standing             (-1.3261)\n",
            "   training             (-1.2019)\n",
            "   casual               (-1.1345)\n",
            "   performance          (-1.0702)\n",
            "   women                (-1.0303)\n",
            "   day                  (-1.0033)\n",
            "   uniform              (-0.9898)\n",
            "   group                (-0.9548)\n",
            "   happy                (-0.9269)\n",
            "   high                 (-0.9143)\n",
            "\n",
            "============================================================\n",
            "MODEL 2: Using DESCRIPTION TEXT\n",
            "============================================================\n",
            "   ‚ÑπÔ∏è  Duration: filled 10 missing values with median (9.0)\n",
            "\n",
            "============================================================\n",
            "MODEL: Description + Duration\n",
            "============================================================\n",
            "Training samples: 800\n",
            "Testing samples: 200\n",
            "Number of features: 101\n",
            "\n",
            "üìä ACCURACY: 0.9750 (97.50%)\n",
            "   (Formula: 1 - 5/200 = 0.9750)\n",
            "\n",
            "üìã CONFUSION MATRIX:\n",
            "                  Predicted\n",
            "                  Low(0)  High(1)\n",
            "Actual  Low(0)      95       5\n",
            "        High(1)      0     100\n",
            "\n",
            "üìà CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Low $$       1.00      0.95      0.97       100\n",
            "     High $$       0.95      1.00      0.98       100\n",
            "\n",
            "    accuracy                           0.97       200\n",
            "   macro avg       0.98      0.97      0.97       200\n",
            "weighted avg       0.98      0.97      0.97       200\n",
            "\n",
            "\n",
            "‚úì Confusion matrix saved as: confusion_matrix_Description__Duration.png\n",
            "\n",
            "üîù TOP 15 WORDS PREDICTING HIGH FUNDRAISING:\n",
            "   dedication           (+1.9196)\n",
            "   people               (+1.7773)\n",
            "   donated              (+1.4766)\n",
            "   incredible           (+1.4610)\n",
            "   raised               (+1.3569)\n",
            "   2025                 (+1.3304)\n",
            "   soccer               (+1.2640)\n",
            "   kids                 (+1.2233)\n",
            "   fees                 (+1.2097)\n",
            "   sport                (+1.1882)\n",
            "   donation             (+0.9481)\n",
            "   just                 (+0.9244)\n",
            "   chance               (+0.7668)\n",
            "   field                (+0.7538)\n",
            "   football             (+0.7487)\n",
            "\n",
            "üîª TOP 15 WORDS PREDICTING LOW FUNDRAISING:\n",
            "   expenses             (-2.4719)\n",
            "   game                 (-2.3339)\n",
            "   10                   (-2.1520)\n",
            "   sports               (-1.8474)\n",
            "   championships        (-1.7554)\n",
            "   family               (-1.6869)\n",
            "   hi                   (-1.6814)\n",
            "   thank                (-1.6017)\n",
            "   training             (-1.4634)\n",
            "   equipment            (-1.3855)\n",
            "   athletes             (-1.1181)\n",
            "   goal                 (-1.0262)\n",
            "   gofundme             (-0.9473)\n",
            "   compete              (-0.8481)\n",
            "   volleyball           (-0.8261)\n",
            "\n",
            "============================================================\n",
            "MODEL 3: Using COMBINED (Image Labels + Description)\n",
            "============================================================\n",
            "   ‚ÑπÔ∏è  Duration: filled 10 missing values with median (9.0)\n",
            "\n",
            "============================================================\n",
            "MODEL: Combined + Duration\n",
            "============================================================\n",
            "Training samples: 800\n",
            "Testing samples: 200\n",
            "Number of features: 101\n",
            "\n",
            "üìä ACCURACY: 0.9850 (98.50%)\n",
            "   (Formula: 1 - 3/200 = 0.9850)\n",
            "\n",
            "üìã CONFUSION MATRIX:\n",
            "                  Predicted\n",
            "                  Low(0)  High(1)\n",
            "Actual  Low(0)      97       3\n",
            "        High(1)      0     100\n",
            "\n",
            "üìà CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Low $$       1.00      0.97      0.98       100\n",
            "     High $$       0.97      1.00      0.99       100\n",
            "\n",
            "    accuracy                           0.98       200\n",
            "   macro avg       0.99      0.98      0.98       200\n",
            "weighted avg       0.99      0.98      0.98       200\n",
            "\n",
            "\n",
            "‚úì Confusion matrix saved as: confusion_matrix_Combined__Duration.png\n",
            "\n",
            "üîù TOP 15 WORDS PREDICTING HIGH FUNDRAISING:\n",
            "   read                 (+2.0915)\n",
            "   fees                 (+1.8599)\n",
            "   2025                 (+1.7273)\n",
            "   sport                (+1.3740)\n",
            "   football             (+1.2822)\n",
            "   photo                (+1.2348)\n",
            "   raised               (+1.1912)\n",
            "   coaches              (+1.1830)\n",
            "   just                 (+1.0647)\n",
            "   make                 (+1.0423)\n",
            "   soccer               (+0.9963)\n",
            "   usa                  (+0.9377)\n",
            "   competitive          (+0.9318)\n",
            "   represent            (+0.9001)\n",
            "   ve                   (+0.8989)\n",
            "\n",
            "üîª TOP 15 WORDS PREDICTING LOW FUNDRAISING:\n",
            "   hi                   (-1.9581)\n",
            "   expenses             (-1.9387)\n",
            "   family               (-1.8517)\n",
            "   training             (-1.7211)\n",
            "   thank                (-1.7066)\n",
            "   game                 (-1.6419)\n",
            "   donate               (-1.6227)\n",
            "   players              (-1.6023)\n",
            "   organized            (-1.3507)\n",
            "   gofundme             (-1.3339)\n",
            "   equipment            (-1.1276)\n",
            "   happy                (-1.0753)\n",
            "   goal                 (-1.0600)\n",
            "   women                (-1.0034)\n",
            "   teams                (-0.9358)\n",
            "\n",
            "============================================================\n",
            "üìä FINAL COMPARISON\n",
            "============================================================\n",
            "                  Model  Accuracy  Features\n",
            "Image Labels + Duration     0.840       101\n",
            " Description + Duration     0.975       101\n",
            "    Combined + Duration     0.985       101\n",
            "\n",
            "üèÜ BEST MODEL: Combined + Duration\n",
            "   Accuracy: 0.9850 (98.50%)\n",
            "\n",
            "============================================================\n",
            "üí° CONCLUSIONS\n",
            "============================================================\n",
            "\n",
            "1. FEATURE COMPARISON:\n",
            "   ‚Üí Text descriptions are MORE predictive than image labels\n",
            "   ‚Üí The story/narrative matters more than visuals\n",
            "\n",
            "2. COMBINATION EFFECT:\n",
            "   ‚Üí Combining features IMPROVES accuracy by 0.0100\n",
            "   ‚Üí Both visual and textual elements contribute unique information\n",
            "\n",
            "3. DURATION IMPACT:\n",
            "   ‚Üí Duration is included as a feature in all models\n",
            "   ‚Üí Longer campaigns may have more time to accumulate donations\n",
            "\n",
            "4. OVERALL MODEL PERFORMANCE:\n",
            "   ‚Üí 98.5% accuracy is GOOD for this prediction task\n",
            "   ‚Üí The model can help predict successful campaigns\n",
            "\n",
            "‚úì Saved comparison to 'model_comparison.csv'\n",
            "\n",
            "============================================================\n",
            "‚úÖ TASKS C & D COMPLETE!\n",
            "============================================================\n",
            "\n",
            "Generated files:\n",
            "  ‚Ä¢ campaigns_with_binary.csv\n",
            "  ‚Ä¢ confusion_matrix_Image_Labels_Duration.png\n",
            "  ‚Ä¢ confusion_matrix_Description_Duration.png\n",
            "  ‚Ä¢ confusion_matrix_Combined_Duration.png\n",
            "  ‚Ä¢ model_comparison.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# TASK C: CREATE BINARY COLUMN\n",
        "# ============================================\n",
        "\n",
        "def create_binary_target(df):\n",
        "    \"\"\"\n",
        "    Create binary column: 1 = high $$ (above median), 0 = low $$ (below median)\n",
        "    \"\"\"\n",
        "    median_amount = df['amount_raised'].median()\n",
        "    df['binary'] = (df['amount_raised'] >= median_amount).astype(int)\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TASK C: Binary Target Variable Created\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Median amount raised: ${median_amount:,.2f}\")\n",
        "    print(f\"\\nClass distribution:\")\n",
        "    print(df['binary'].value_counts().sort_index())\n",
        "    print(f\"\\nHigh $$ (binary=1): {(df['binary'] == 1).sum()} campaigns\")\n",
        "    print(f\"Low $$ (binary=0): {(df['binary'] == 0).sum()} campaigns\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return df, median_amount\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# TASK D: LOGISTIC REGRESSION MODELS\n",
        "# ============================================\n",
        "\n",
        "def prepare_features(df, text_column, include_duration=True, max_features=100):\n",
        "    \"\"\"\n",
        "    Convert text to Bag-of-Words features and optionally add duration\n",
        "    FIXED: Now handles NaN values properly and returns complete feature names\n",
        "    \"\"\"\n",
        "    # Fill NaN values in text column with empty string\n",
        "    text_data = df[text_column].fillna('')\n",
        "\n",
        "    # Create Bag of Words from text\n",
        "    vectorizer = CountVectorizer(\n",
        "        max_features=max_features,  # Top 100 most common words\n",
        "        lowercase=True,\n",
        "        strip_accents='unicode',\n",
        "        stop_words='english'  # Remove common words like 'the', 'and', etc.\n",
        "    )\n",
        "\n",
        "    # Transform text to BoW features\n",
        "    bow_features = vectorizer.fit_transform(text_data)\n",
        "    feature_names = list(vectorizer.get_feature_names_out())  # Convert to list\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    X = pd.DataFrame(bow_features.toarray(), columns=feature_names, index=df.index)\n",
        "\n",
        "    # Add duration as a feature if requested\n",
        "    if include_duration:\n",
        "        # Fill NaN values in duration_days with median\n",
        "        duration_median = df['duration_days'].median()\n",
        "        X['duration_days'] = df['duration_days'].fillna(duration_median).values\n",
        "\n",
        "        # Add 'duration_days' to feature names list\n",
        "        feature_names.append('duration_days')\n",
        "\n",
        "        print(\n",
        "            f\"   ‚ÑπÔ∏è  Duration: filled {df['duration_days'].isna().sum()} missing values with median ({duration_median})\")\n",
        "\n",
        "    y = df['binary'].values\n",
        "\n",
        "    # Double-check for any remaining NaN values\n",
        "    if X.isna().any().any():\n",
        "        print(\"   ‚ö†Ô∏è  WARNING: Still found NaN values, filling with 0\")\n",
        "        X = X.fillna(0)\n",
        "\n",
        "    # Convert feature_names back to numpy array for consistency\n",
        "    feature_names = np.array(feature_names)\n",
        "\n",
        "    return X, y, vectorizer, feature_names\n",
        "\n",
        "def train_and_evaluate_model(X, y, model_name):\n",
        "    \"\"\"\n",
        "    Train logistic regression and evaluate performance\n",
        "    \"\"\"\n",
        "    # Double-check for NaN before splitting\n",
        "    assert not X.isna().any().any(), \"X contains NaN values!\"\n",
        "    assert not np.isnan(y).any(), \"y contains NaN values!\"\n",
        "\n",
        "    # Split data: 80% train, 20% test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Train Logistic Regression\n",
        "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Alternative accuracy calculation as specified in assignment\n",
        "    prediction_errors = np.sum(y_test != y_pred)\n",
        "    total_cases = len(y_test)\n",
        "    accuracy_alt = 1 - (prediction_errors / total_cases)\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"MODEL: {model_name}\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Testing samples: {len(X_test)}\")\n",
        "    print(f\"Number of features: {X.shape[1]}\")\n",
        "\n",
        "    print(f\"\\nüìä ACCURACY: {accuracy:.4f} ({accuracy * 100:.2f}%)\")\n",
        "    print(f\"   (Formula: 1 - {prediction_errors}/{total_cases} = {accuracy_alt:.4f})\")\n",
        "\n",
        "    print(f\"\\nüìã CONFUSION MATRIX:\")\n",
        "    print(f\"                  Predicted\")\n",
        "    print(f\"                  Low(0)  High(1)\")\n",
        "    print(f\"Actual  Low(0)     {cm[0, 0]:3d}     {cm[0, 1]:3d}\")\n",
        "    print(f\"        High(1)    {cm[1, 0]:3d}     {cm[1, 1]:3d}\")\n",
        "\n",
        "    print(f\"\\nüìà CLASSIFICATION REPORT:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Low $$', 'High $$']))\n",
        "\n",
        "    # Plot confusion matrix - FIXED: escape dollar signs for matplotlib\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Use raw string or escape dollar signs to avoid LaTeX interpretation\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Low Money', 'High Money'],  # Changed labels\n",
        "                yticklabels=['Low Money', 'High Money'])  # Changed labels\n",
        "\n",
        "    plt.title(f'Confusion Matrix: {model_name}')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    filename = f'confusion_matrix_{model_name.replace(\" \", \"_\").replace(\"+\", \"\").replace(\"  \", \"_\")}.png'\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"\\n‚úì Confusion matrix saved as: {filename}\")\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'accuracy': accuracy,\n",
        "        'confusion_matrix': cm,\n",
        "        'predictions': y_pred,\n",
        "        'y_test': y_test,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test\n",
        "    }\n",
        "\n",
        "\n",
        "def get_top_predictive_words(model, feature_names, top_n=15):\n",
        "    \"\"\"\n",
        "    Get the most predictive words for high vs low fundraising\n",
        "    \"\"\"\n",
        "    # Get coefficients\n",
        "    coefs = model.coef_[0]\n",
        "\n",
        "    # Filter out 'duration_days' if present\n",
        "    mask = np.array([name != 'duration_days' for name in feature_names])\n",
        "    filtered_coefs = coefs[mask]\n",
        "    filtered_names = feature_names[mask]\n",
        "\n",
        "    if len(filtered_coefs) == 0:\n",
        "        print(\"\\n‚ö†Ô∏è  No text features to analyze (only duration)\")\n",
        "        return\n",
        "\n",
        "    # Words that predict HIGH fundraising (positive coefficients)\n",
        "    top_high_idx = np.argsort(filtered_coefs)[-top_n:][::-1]\n",
        "    top_high_words = [(filtered_names[i], filtered_coefs[i]) for i in top_high_idx]\n",
        "\n",
        "    # Words that predict LOW fundraising (negative coefficients)\n",
        "    top_low_idx = np.argsort(filtered_coefs)[:top_n]\n",
        "    top_low_words = [(filtered_names[i], filtered_coefs[i]) for i in top_low_idx]\n",
        "\n",
        "    print(f\"\\nüîù TOP {min(top_n, len(top_high_words))} WORDS PREDICTING HIGH FUNDRAISING:\")\n",
        "    for word, coef in top_high_words:\n",
        "        print(f\"   {word:20s} ({coef:+.4f})\")\n",
        "\n",
        "    print(f\"\\nüîª TOP {min(top_n, len(top_low_words))} WORDS PREDICTING LOW FUNDRAISING:\")\n",
        "    for word, coef in top_low_words:\n",
        "        print(f\"   {word:20s} ({coef:+.4f})\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================\n",
        "\n",
        "def main():\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"GOFUNDME PREDICTIVE ANALYSIS - TASKS C & D\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Load data\n",
        "    print(\"\\nüìÇ Loading data...\")\n",
        "    df = pd.read_csv('campaigns_with_labels.csv')\n",
        "    print(f\"‚úì Loaded {len(df)} campaigns\")\n",
        "\n",
        "    # Check for missing values\n",
        "    print(\"\\nüîç Checking for missing values...\")\n",
        "    missing_summary = df[['image_labels', 'description', 'amount_raised', 'duration_days']].isna().sum()\n",
        "    print(missing_summary)\n",
        "\n",
        "    # TASK C: Create binary target\n",
        "    df, median_amount = create_binary_target(df)\n",
        "\n",
        "    # Save dataset with binary column\n",
        "    df.to_csv('campaigns_with_binary.csv', index=False)\n",
        "    print(f\"\\n‚úì Saved to 'campaigns_with_binary.csv'\")\n",
        "\n",
        "    # ============================================\n",
        "    # TASK D: THREE MODELS\n",
        "    # ============================================\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # MODEL 1: Image Labels Only\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL 1: Using IMAGE_LABELS\")\n",
        "    print(\"=\" * 60)\n",
        "    X1, y1, vec1, features1 = prepare_features(df, 'image_labels', include_duration=True)\n",
        "    results['image_labels'] = train_and_evaluate_model(X1, y1, \"Image Labels + Duration\")\n",
        "    get_top_predictive_words(results['image_labels']['model'], features1)\n",
        "\n",
        "    # MODEL 2: Description Text Only\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL 2: Using DESCRIPTION TEXT\")\n",
        "    print(\"=\" * 60)\n",
        "    X2, y2, vec2, features2 = prepare_features(df, 'description', include_duration=True)\n",
        "    results['description'] = train_and_evaluate_model(X2, y2, \"Description + Duration\")\n",
        "    get_top_predictive_words(results['description']['model'], features2)\n",
        "\n",
        "    # MODEL 3: Combined (Image Labels + Description)\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL 3: Using COMBINED (Image Labels + Description)\")\n",
        "    print(\"=\" * 60)\n",
        "    # Concatenate image_labels and description\n",
        "    df['combined_text'] = df['image_labels'].fillna('') + ' ' + df['description'].fillna('')\n",
        "    X3, y3, vec3, features3 = prepare_features(df, 'combined_text', include_duration=True)\n",
        "    results['combined'] = train_and_evaluate_model(X3, y3, \"Combined + Duration\")\n",
        "    get_top_predictive_words(results['combined']['model'], features3)\n",
        "\n",
        "    # ============================================\n",
        "    # COMPARISON & CONCLUSIONS\n",
        "    # ============================================\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üìä FINAL COMPARISON\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Model': ['Image Labels + Duration', 'Description + Duration', 'Combined + Duration'],\n",
        "        'Accuracy': [\n",
        "            results['image_labels']['accuracy'],\n",
        "            results['description']['accuracy'],\n",
        "            results['combined']['accuracy']\n",
        "        ],\n",
        "        'Features': [X1.shape[1], X2.shape[1], X3.shape[1]]\n",
        "    })\n",
        "\n",
        "    print(comparison_df.to_string(index=False))\n",
        "\n",
        "    # Find best model\n",
        "    best_model_name = comparison_df.loc[comparison_df['Accuracy'].idxmax(), 'Model']\n",
        "    best_accuracy = comparison_df['Accuracy'].max()\n",
        "\n",
        "    print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
        "    print(f\"   Accuracy: {best_accuracy:.4f} ({best_accuracy * 100:.2f}%)\")\n",
        "\n",
        "    # ============================================\n",
        "    # CONCLUSIONS\n",
        "    # ============================================\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üí° CONCLUSIONS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(\"\\n1. FEATURE COMPARISON:\")\n",
        "    if results['image_labels']['accuracy'] > results['description']['accuracy']:\n",
        "        print(\"   ‚Üí Image labels are MORE predictive than text descriptions\")\n",
        "        print(\"   ‚Üí Visual elements matter more for fundraising success\")\n",
        "    else:\n",
        "        print(\"   ‚Üí Text descriptions are MORE predictive than image labels\")\n",
        "        print(\"   ‚Üí The story/narrative matters more than visuals\")\n",
        "\n",
        "    acc_diff = abs(results['combined']['accuracy'] - max(results['image_labels']['accuracy'],\n",
        "                                                         results['description']['accuracy']))\n",
        "\n",
        "    print(f\"\\n2. COMBINATION EFFECT:\")\n",
        "    if results['combined']['accuracy'] > max(results['image_labels']['accuracy'],\n",
        "                                             results['description']['accuracy']):\n",
        "        print(f\"   ‚Üí Combining features IMPROVES accuracy by {acc_diff:.4f}\")\n",
        "        print(\"   ‚Üí Both visual and textual elements contribute unique information\")\n",
        "    else:\n",
        "        print(\"   ‚Üí Combining features does NOT significantly improve accuracy\")\n",
        "        print(\"   ‚Üí One feature type captures most of the predictive power\")\n",
        "\n",
        "    print(f\"\\n3. DURATION IMPACT:\")\n",
        "    print(\"   ‚Üí Duration is included as a feature in all models\")\n",
        "    print(\"   ‚Üí Longer campaigns may have more time to accumulate donations\")\n",
        "\n",
        "    print(f\"\\n4. OVERALL MODEL PERFORMANCE:\")\n",
        "    if best_accuracy > 0.70:\n",
        "        print(f\"   ‚Üí {best_accuracy * 100:.1f}% accuracy is GOOD for this prediction task\")\n",
        "        print(\"   ‚Üí The model can help predict successful campaigns\")\n",
        "    elif best_accuracy > 0.60:\n",
        "        print(f\"   ‚Üí {best_accuracy * 100:.1f}% accuracy is MODERATE\")\n",
        "        print(\"   ‚Üí Better than random, but room for improvement\")\n",
        "    else:\n",
        "        print(f\"   ‚Üí {best_accuracy * 100:.1f}% accuracy is LIMITED\")\n",
        "        print(\"   ‚Üí Other factors (not in data) may drive success\")\n",
        "\n",
        "    # Save comparison\n",
        "    comparison_df.to_csv('model_comparison.csv', index=False)\n",
        "    print(f\"\\n‚úì Saved comparison to 'model_comparison.csv'\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úÖ TASKS C & D COMPLETE!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nGenerated files:\")\n",
        "    print(\"  ‚Ä¢ campaigns_with_binary.csv\")\n",
        "    print(\"  ‚Ä¢ confusion_matrix_Image_Labels_Duration.png\")\n",
        "    print(\"  ‚Ä¢ confusion_matrix_Description_Duration.png\")\n",
        "    print(\"  ‚Ä¢ confusion_matrix_Combined_Duration.png\")\n",
        "    print(\"  ‚Ä¢ model_comparison.csv\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3: TOP 15 WORDS PREDICTING HIGH FUNDRAISING:\n",
        "   read                 (+2.0915)\n",
        "   fees                 (+1.8599)\n",
        "   2025                 (+1.7273)\n",
        "   sport                (+1.3740)\n",
        "   football             (+1.2822)\n",
        "   photo                (+1.2348)\n",
        "   raised               (+1.1912)\n",
        "   coaches              (+1.1830)\n",
        "   just                 (+1.0647)\n",
        "   make                 (+1.0423)\n",
        "   soccer               (+0.9963)\n",
        "   usa                  (+0.9377)\n",
        "   competitive          (+0.9318)\n",
        "   represent            (+0.9001)\n",
        "   ve                   (+0.8989)\n",
        "\n",
        "Model 3: TOP 15 WORDS PREDICTING LOW FUNDRAISING:\n",
        "   hi                   (-1.9581)\n",
        "   expenses             (-1.9387)\n",
        "   family               (-1.8517)\n",
        "   training             (-1.7211)\n",
        "   thank                (-1.7066)\n",
        "   game                 (-1.6419)\n",
        "   donate               (-1.6227)\n",
        "   players              (-1.6023)\n",
        "   organized            (-1.3507)\n",
        "   gofundme             (-1.3339)\n",
        "   equipment            (-1.1276)\n",
        "   happy                (-1.0753)\n",
        "   goal                 (-1.0600)\n",
        "   women                (-1.0034)\n",
        "   teams                (-0.9358)"
      ],
      "metadata": {
        "id": "gkMm9OG1LG8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Comparison\n",
        "- Image Labels + Duration ->    Accuracy: 0.840       Features: 101\n",
        "- Description + Duration  ->   Accuracy: 0.975       Features: 101\n",
        "- Combined + Duration ->    Accuracy: 0.985       Features: 101"
      ],
      "metadata": {
        "id": "IdHw7VssKuRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusions:\n",
        "\n",
        "1. Feature Comparison:\n",
        "   ‚Üí Text descriptions are MORE predictive than image labels\n",
        "   ‚Üí The story/narrative matters more than visuals\n",
        "\n",
        "2. Combination Effect:\n",
        "   ‚Üí Combining features IMPROVES accuracy by 0.0100\n",
        "   ‚Üí Both visual and textual elements contribute unique information\n",
        "\n",
        "3. Duration Impact:\n",
        "   ‚Üí Duration is included as a feature in all models\n",
        "   ‚Üí Longer campaigns may have more time to accumulate donations\n",
        "\n",
        "4. Overall Model Performance:\n",
        "   ‚Üí 98.5% accuracy is GOOD for this prediction task\n",
        "   ‚Üí The model can help predict successful campaigns"
      ],
      "metadata": {
        "id": "2fSfAlUwKkXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK E: TOPIC MODELING (LDA)\n",
        "# ============================================\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import numpy as np\n",
        "\n",
        "# 1Ô∏è‚É£ Load the dataset from Task D\n",
        "df = pd.read_csv(\"campaigns_with_binary.csv\")\n",
        "\n",
        "# 2Ô∏è‚É£ Combine the text columns (best-performing combo from Task D)\n",
        "df[\"combined_text\"] = df[\"image_labels\"].fillna('') + ' ' + df[\"description\"].fillna('')\n",
        "\n",
        "# 3Ô∏è‚É£ Vectorize text using Bag-of-Words\n",
        "vectorizer = CountVectorizer(\n",
        "    max_features=1000,\n",
        "    lowercase=True,\n",
        "    stop_words='english',\n",
        "    strip_accents='unicode'\n",
        ")\n",
        "X = vectorizer.fit_transform(df[\"combined_text\"])\n",
        "\n",
        "# 4Ô∏è‚É£ Fit Latent Dirichlet Allocation (LDA) with 5 topics\n",
        "lda = LatentDirichletAllocation(\n",
        "    n_components=5,\n",
        "    random_state=42,\n",
        "    learning_method='batch',\n",
        "    max_iter=20\n",
        ")\n",
        "lda.fit(X)\n",
        "\n",
        "# 5Ô∏è‚É£ Display top words for each topic\n",
        "def display_topics(model, feature_names, n_top_words=10):\n",
        "    print(\"\\n============================================================\")\n",
        "    print(\"TOP WORDS PER TOPIC\")\n",
        "    print(\"============================================================\")\n",
        "    for idx, topic in enumerate(model.components_):\n",
        "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
        "        print(f\"Topic {idx + 1}: {', '.join(top_words)}\")\n",
        "\n",
        "display_topics(lda, vectorizer.get_feature_names_out(), n_top_words=10)\n",
        "\n",
        "# 6Ô∏è‚É£ Get topic weights for each campaign\n",
        "topic_weights = lda.transform(X)\n",
        "topic_cols = [f\"Topic_{i+1}\" for i in range(lda.n_components)]\n",
        "topic_df = pd.DataFrame(topic_weights, columns=topic_cols)\n",
        "df = pd.concat([df, topic_df], axis=1)\n",
        "\n",
        "# 7Ô∏è‚É£ Compare top (Q4) vs bottom (Q1) fundraising quartiles\n",
        "q1_cutoff = df[\"amount_raised\"].quantile(0.25)\n",
        "q4_cutoff = df[\"amount_raised\"].quantile(0.75)\n",
        "\n",
        "low_df = df[df[\"amount_raised\"] <= q1_cutoff]\n",
        "high_df = df[df[\"amount_raised\"] >= q4_cutoff]\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    \"Topic\": topic_cols,\n",
        "    \"Low_Q1_Avg\": [low_df[col].mean() for col in topic_cols],\n",
        "    \"High_Q4_Avg\": [high_df[col].mean() for col in topic_cols]\n",
        "})\n",
        "\n",
        "print(\"\\n============================================================\")\n",
        "print(\"AVERAGE TOPIC WEIGHTS BY FUNDRAISING QUARTILE\")\n",
        "print(\"============================================================\")\n",
        "print(comparison.round(3).to_string(index=False))\n",
        "\n",
        "# 8Ô∏è‚É£ Save the results\n",
        "df.to_csv(\"campaigns_with_topics.csv\", index=False)\n",
        "comparison.to_csv(\"topic_quartile_comparison.csv\", index=False)\n",
        "\n",
        "print(\"\\n============================================================\")\n",
        "print(\"‚úÖ TASK E COMPLETE!\")\n",
        "print(\"============================================================\")\n",
        "print(\"Generated files:\")\n",
        "print(\"  ‚Ä¢ campaigns_with_topics.csv\")\n",
        "print(\"  ‚Ä¢ topic_quartile_comparison.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFjhfDzCnHsQ",
        "outputId": "93940cd2-a9b6-4960-bdde-7890da65f1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TOP WORDS PER TOPIC\n",
            "============================================================\n",
            "Topic 1: share, organizer, donate, fundraiser, sports, help, support, goal, donation, protected\n",
            "Topic 2: sports, fundraiser, donate, team, share, organizer, support, football, goal, youth\n",
            "Topic 3: organizer, team, sports, share, fundraiser, soccer, donate, support, donations, goal\n",
            "Topic 4: fundraiser, sports, team, organizer, donate, support, share, help, goal, gofundme\n",
            "Topic 5: team, fundraiser, sports, donate, share, organizer, support, goal, help, donation\n",
            "\n",
            "============================================================\n",
            "AVERAGE TOPIC WEIGHTS BY FUNDRAISING QUARTILE\n",
            "============================================================\n",
            "  Topic  Low_Q1_Avg  High_Q4_Avg\n",
            "Topic_1       0.134        0.170\n",
            "Topic_2       0.221        0.114\n",
            "Topic_3       0.079        0.225\n",
            "Topic_4       0.141        0.250\n",
            "Topic_5       0.425        0.241\n",
            "\n",
            "============================================================\n",
            "‚úÖ TASK E COMPLETE!\n",
            "============================================================\n",
            "Generated files:\n",
            "  ‚Ä¢ campaigns_with_topics.csv\n",
            "  ‚Ä¢ topic_quartile_comparison.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK E: TOPIC MODELING (LDA) ‚Äî 3 Topics Version\n",
        "# ============================================\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import numpy as np\n",
        "\n",
        "# 1Ô∏è‚É£ Load the dataset from Task D\n",
        "df = pd.read_csv(\"campaigns_with_binary.csv\")\n",
        "\n",
        "# 2Ô∏è‚É£ Combine the text columns (best-performing combo from Task D)\n",
        "df[\"combined_text\"] = df[\"image_labels\"].fillna('') + ' ' + df[\"description\"].fillna('')\n",
        "\n",
        "# 3Ô∏è‚É£ Vectorize text using Bag-of-Words\n",
        "vectorizer = CountVectorizer(\n",
        "    max_features=1500,     # slightly larger vocabulary for more variety\n",
        "    lowercase=True,\n",
        "    stop_words='english',\n",
        "    strip_accents='unicode'\n",
        ")\n",
        "X = vectorizer.fit_transform(df[\"combined_text\"])\n",
        "\n",
        "# 4Ô∏è‚É£ Fit Latent Dirichlet Allocation (LDA) with 3 topics\n",
        "lda = LatentDirichletAllocation(\n",
        "    n_components=3,        # <‚Äî reduced from 5 to 3 for broader, cleaner themes\n",
        "    random_state=42,\n",
        "    learning_method='batch',\n",
        "    max_iter=30            # a few extra passes for stability\n",
        ")\n",
        "lda.fit(X)\n",
        "\n",
        "# 5Ô∏è‚É£ Display top words for each topic\n",
        "def display_topics(model, feature_names, n_top_words=10):\n",
        "    print(\"\\n============================================================\")\n",
        "    print(\"TOP WORDS PER TOPIC (3-Topic Model)\")\n",
        "    print(\"============================================================\")\n",
        "    for idx, topic in enumerate(model.components_):\n",
        "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
        "        print(f\"Topic {idx + 1}: {', '.join(top_words)}\")\n",
        "\n",
        "display_topics(lda, vectorizer.get_feature_names_out(), n_top_words=10)\n",
        "\n",
        "# 6Ô∏è‚É£ Get topic weights for each campaign\n",
        "topic_weights = lda.transform(X)\n",
        "topic_cols = [f\"Topic_{i+1}\" for i in range(lda.n_components)]\n",
        "topic_df = pd.DataFrame(topic_weights, columns=topic_cols)\n",
        "df = pd.concat([df, topic_df], axis=1)\n",
        "\n",
        "# 7Ô∏è‚É£ Compare top (Q4) vs bottom (Q1) fundraising quartiles\n",
        "q1_cutoff = df[\"amount_raised\"].quantile(0.25)\n",
        "q4_cutoff = df[\"amount_raised\"].quantile(0.75)\n",
        "\n",
        "low_df = df[df[\"amount_raised\"] <= q1_cutoff]\n",
        "high_df = df[df[\"amount_raised\"] >= q4_cutoff]\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    \"Topic\": topic_cols,\n",
        "    \"Low_Q1_Avg\": [low_df[col].mean() for col in topic_cols],\n",
        "    \"High_Q4_Avg\": [high_df[col].mean() for col in topic_cols]\n",
        "})\n",
        "\n",
        "print(\"\\n============================================================\")\n",
        "print(\"AVERAGE TOPIC WEIGHTS BY FUNDRAISING QUARTILE\")\n",
        "print(\"============================================================\")\n",
        "print(comparison.round(3).to_string(index=False))\n",
        "\n",
        "# 8Ô∏è‚É£ Save the results\n",
        "df.to_csv(\"campaigns_with_topics_3topics.csv\", index=False)\n",
        "comparison.to_csv(\"topic_quartile_comparison_3topics.csv\", index=False)\n",
        "\n",
        "print(\"\\n============================================================\")\n",
        "print(\"‚úÖ TASK E (3-Topic Model) COMPLETE!\")\n",
        "print(\"============================================================\")\n",
        "print(\"Generated files:\")\n",
        "print(\"  ‚Ä¢ campaigns_with_topics_3topics.csv\")\n",
        "print(\"  ‚Ä¢ topic_quartile_comparison_3topics.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19YY5FDJIIse",
        "outputId": "da030c9f-15fb-4f51-a67b-a7f823138c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TOP WORDS PER TOPIC (3-Topic Model)\n",
            "============================================================\n",
            "Topic 1: team, sports, fundraiser, share, donate, organizer, support, goal, help, donations\n",
            "Topic 2: fundraiser, donate, share, organizer, support, sports, team, help, goal, donation\n",
            "Topic 3: sports, fundraiser, donate, team, organizer, share, support, goal, help, donations\n",
            "\n",
            "============================================================\n",
            "AVERAGE TOPIC WEIGHTS BY FUNDRAISING QUARTILE\n",
            "============================================================\n",
            "  Topic  Low_Q1_Avg  High_Q4_Avg\n",
            "Topic_1       0.359        0.238\n",
            "Topic_2       0.353        0.402\n",
            "Topic_3       0.288        0.360\n",
            "\n",
            "============================================================\n",
            "‚úÖ TASK E (3-Topic Model) COMPLETE!\n",
            "============================================================\n",
            "Generated files:\n",
            "  ‚Ä¢ campaigns_with_topics_3topics.csv\n",
            "  ‚Ä¢ topic_quartile_comparison_3topics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We performed Latent Dirichlet Allocation (LDA) on the combined text of image labels and descriptions to identify common themes among GoFundMe campaigns. After testing both a 3-topic and a 5-topic model, the 5-topic configuration was retained because it produced more interpretable and differentiated clusters of words, even though overlap remained due to the repetitive nature of fundraising language (for example, frequent use of ‚Äúdonate,‚Äù ‚Äúhelp,‚Äù and ‚Äúsupport‚Äù). The 3-topic version collapsed several subtle patterns into broader categories, while the 5-topic model revealed clearer distinctions such as youth-oriented sports campaigns versus general community fundraisers.\n",
        "\n",
        "The five topics were interpreted and labeled as follows:\n",
        "Topic 1 ‚Äì **Community Outreach and Sharing**\n",
        "Topic 2 ‚Äì **Youth Sports Fundraisers**\n",
        "Topic 3 ‚Äì **Club or Soccer Campaigns**\n",
        "Topic 4 ‚Äì **General Fundraising Appeals**\n",
        "Topic 5 ‚Äì **Team Spirit and Collective Support**\n",
        "\n",
        "When comparing topic weights between high- and low-fundraising quartiles, higher-performing campaigns showed greater emphasis on Topics 3 and 4, suggesting that broader and sport-specific appeals attract more donations. In contrast, lower-fundraising campaigns leaned toward Topics 2 and 5, which focus more narrowly on smaller youth or team-based efforts. Overall, the 5-topic model offered clearer interpretability and stronger insights into how different campaign narratives relate to fundraising success.\n"
      ],
      "metadata": {
        "id": "L0KMEyEJJG-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part F"
      ],
      "metadata": {
        "id": "4da-javz4ldW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See attached .docx file\n"
      ],
      "metadata": {
        "id": "_7TVAHg45xmj"
      }
    }
  ]
}